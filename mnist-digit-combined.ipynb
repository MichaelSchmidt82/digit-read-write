{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Shapes:\n",
      "img_shape:\t (28, 28, 1)\n",
      "x_reader:\t (60000, 784)\n",
      "y_reader:\t (60000, 10)\n",
      "x_writer:\t (60000, 28, 28, 1)\n",
      "y_writer:\t (60000, 1)\n"
     ]
    }
   ],
   "source": [
    "## Imports ##\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras import layers, optimizers, Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from IPython.display import display, SVG\n",
    "\n",
    "## Constants\n",
    "num_classes = 10\n",
    "img_rows, img_cols, img_chan = 28, 28, 1\n",
    "img_shape = (img_rows, img_cols, img_chan)\n",
    "\n",
    "metrics = ['accuracy']\n",
    "verbose = 0\n",
    "\n",
    "## Data ##\n",
    "(x_reader, y_reader), (_, _) = mnist.load_data()\n",
    "x_writer, y_writer = x_reader, y_reader\n",
    "\n",
    "x_reader = x_reader.reshape(x_reader.shape[0], img_rows * img_cols)\n",
    "x_reader = x_reader.astype(np.float32) / 255.0\n",
    "\n",
    "x_writer = (x_writer.astype(np.float32) - 127.5) / 127.5 # Rescale -1 to 1\n",
    "x_writer = np.expand_dims(x_writer, axis=3)\n",
    "\n",
    "y_reader = to_categorical(y_reader, num_classes)\n",
    "y_writer = y_writer.reshape(-1, 1)\n",
    "\n",
    "history = [[],[],[],[]]\n",
    "\n",
    "## Hyperparameters ##\n",
    "# Reading\n",
    "reader_epochs = 40\n",
    "reader_validation_split = 0.2\n",
    "reader_batch_size = 512\n",
    "reader_kernel_initializer = RandomUniform(minval=0.0000001, \n",
    "                                          maxval=0.0001, \n",
    "                                          seed=None)\n",
    "reader_optimizer = optimizers.Adam()\n",
    "reader_loss = categorical_crossentropy\n",
    "\n",
    "# Writing\n",
    "writer_epochs = 22000\n",
    "writer_latent_dim = 100\n",
    "writer_batch_size = 32\n",
    "writer_half_batch = int(writer_batch_size / 2)\n",
    "\n",
    "writer_optimizer = optimizers.Adam(lr=0.0002,      # lr default:         0.001\n",
    "                                    beta_1=0.5,     # beta_1 default:     0.9\n",
    "                                    beta_2=0.999, \n",
    "                                    epsilon=None, \n",
    "                                    decay=0.0, \n",
    "                                    amsgrad=False)\n",
    "writer_loss = ['binary_crossentropy']\n",
    "\n",
    "grader_optimizer = writer_optimizer\n",
    "grader_loss = ['binary_crossentropy', 'sparse_categorical_crossentropy']\n",
    "\n",
    "school_optimizer = grader_optimizer\n",
    "school_loss = ['binary_crossentropy','sparse_categorical_crossentropy']\n",
    "\n",
    "print(\"Matrix Shapes:\")\n",
    "print(\"img_shape:\\t\", img_shape)\n",
    "print('x_reader:\\t', x_reader.shape)\n",
    "print('y_reader:\\t', y_reader.shape)\n",
    "print('x_writer:\\t', x_writer.shape)\n",
    "print('y_writer:\\t', y_writer.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Sequential()\n",
    "reader.add(layers.Dense(320, activation='relu', \n",
    "                        kernel_initializer=reader_kernel_initializer, \n",
    "                        input_shape=[x_reader.shape[1]]))\n",
    "reader.add(layers.Dropout(0.66))\n",
    "reader.add(layers.Dense(num_classes, activation='softmax'))\n",
    "reader.compile(loss=reader_loss, \n",
    "               optimizer=reader_optimizer, \n",
    "               metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writer models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Layers: 2 layers: noise, class_labels\n",
    "noise = layers.Input(shape=(writer_latent_dim,))\n",
    "label = layers.Input(shape=(1,), dtype='int32')\n",
    "\n",
    "# Create an embedding\n",
    "label_embedding = layers.Embedding(num_classes, writer_latent_dim)(label)\n",
    "label_embedding = layers.Flatten()(label_embedding)\n",
    "\n",
    "writer_input = layers.multiply([noise, label_embedding])\n",
    "\n",
    "# Generator hidden layers\n",
    "writer_hidden = layers.Dense(128 * 7 * 7, \n",
    "                             activation='relu', \n",
    "                             input_dim=writer_latent_dim)(writer_input)\n",
    "writer_hidden = layers.Reshape((7, 7, 128))(writer_hidden)\n",
    "writer_hidden = layers.BatchNormalization(momentum=0.8)(writer_hidden)\n",
    "writer_hidden = layers.UpSampling2D()(writer_hidden)\n",
    "writer_hidden = layers.Conv2D(128, \n",
    "                              activation='relu',\n",
    "                              kernel_size=3, \n",
    "                              padding='same')(writer_hidden)\n",
    "writer_hidden = layers.BatchNormalization(momentum=0.8)(writer_hidden)\n",
    "writer_hidden = layers.UpSampling2D()(writer_hidden)\n",
    "writer_hidden = layers.Conv2D(64, \n",
    "                              activation='relu', \n",
    "                              kernel_size=3, \n",
    "                              padding='same')(writer_hidden)\n",
    "writer_hidden = layers.BatchNormalization(momentum=0.8)(writer_hidden)\n",
    "writer_image = layers.Conv2D(img_chan, \n",
    "                              activation='tanh',\n",
    "                              kernel_size=3, \n",
    "                              padding='same')(writer_hidden)\n",
    "\n",
    "# Finalize the model\n",
    "writer = Model([noise, label], writer_image)\n",
    "writer.compile(loss=writer_loss, \n",
    "               optimizer=writer_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader_image = layers.Input(shape=img_shape)\n",
    "\n",
    "grader_hidden = layers.Conv2D(16, \n",
    "                              kernel_size=3, \n",
    "                              strides=2,  \n",
    "                              padding='same', \n",
    "                              input_shape=img_shape)(grader_image)\n",
    "grader_hidden = layers.LeakyReLU(alpha=0.2)(grader_hidden)\n",
    "grader_hidden = layers.Dropout(0.25)(grader_hidden)\n",
    "grader_hidden = layers.Conv2D(32, \n",
    "                              kernel_size=3, \n",
    "                              strides=2, \n",
    "                              padding='same')(grader_hidden)\n",
    "grader_hidden = layers.ZeroPadding2D(padding=((0,1),(0,1)))(grader_hidden)\n",
    "grader_hidden = layers.LeakyReLU(alpha=0.2)(grader_hidden)\n",
    "grader_hidden = layers.Dropout(0.25)(grader_hidden)\n",
    "grader_hidden = layers.BatchNormalization(momentum=0.8)(grader_hidden)\n",
    "grader_hidden = layers.Conv2D(64, \n",
    "                              kernel_size=3, \n",
    "                              strides=2, \n",
    "                              padding='same')(grader_hidden)\n",
    "grader_hidden = layers.LeakyReLU(alpha=0.2)(grader_hidden)\n",
    "grader_hidden = layers.Dropout(0.25)(grader_hidden)\n",
    "grader_hidden = layers.BatchNormalization(momentum=0.8)(grader_hidden)\n",
    "grader_hidden = layers.Conv2D(128, \n",
    "                              kernel_size=3, \n",
    "                              strides=1, \n",
    "                              padding='same')(grader_hidden)\n",
    "grader_hidden = layers.LeakyReLU(alpha=0.2)(grader_hidden)\n",
    "grader_hidden = layers.Dropout(0.25)(grader_hidden)\n",
    "grader_hidden = layers.Flatten()(grader_hidden)\n",
    "\n",
    "grader_valid = layers.Dense(1, \n",
    "                            activation='sigmoid')(grader_hidden)\n",
    "grader_label = layers.Dense(num_classes + 1, \n",
    "                            activation='softmax')(grader_hidden)\n",
    "\n",
    "grader = Model(grader_image, [grader_valid, grader_label])\n",
    "grader.compile(loss=grader_loss, \n",
    "               optimizer=grader_optimizer, \n",
    "               metrics=metrics)\n",
    "\n",
    "# Don't update discriminator during generator training (moving target problem)\n",
    "grader.trainable = False\n",
    "\n",
    "# Don't recompile the discriminator so may still be trained independently...\n",
    "grader_valid, grader_label = grader(writer_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### School house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined model takes generator inputs and has discriminator outputs...\n",
    "school = Model([noise, label], [grader_valid, grader_label])\n",
    "school.compile(loss=school_loss, \n",
    "               optimizer=school_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVG(model_to_dot(reader).create(prog='dot', format='svg'))\n",
    "# SVG(model_to_dot(writer).create(prog='dot', format='svg'))\n",
    "# SVG(model_to_dot(grader).create(prog='dot', format='svg'))\n",
    "# SVG(model_to_dot(school).create(prog='dot', format='svg'))\n",
    "\n",
    "# reader.summary()\n",
    "# writer.summary()\n",
    "# grader.summary()\n",
    "# school.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4283dfe5ae1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m reader_hist = reader.fit(x_train, y_train, \n\u001b[0m\u001b[1;32m      2\u001b[0m                          \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreader_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreader_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          validation_split=validation_split)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "reader_hist = reader.fit(x_train, y_train, \n",
    "                         epochs=reader_epochs, \n",
    "                         batch_size=reader_batch_size, \n",
    "                         verbose=verbose, \n",
    "                         validation_split=validation_split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

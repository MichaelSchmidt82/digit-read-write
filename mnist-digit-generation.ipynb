{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras import layers, optimizers, Model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import display, SVG\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Data\n",
    "(x_train, y_train), (_, _) = mnist.load_data()\n",
    "x_train = (x_train.astype(np.float32) - 127.5) / 127.5 # Rescale -1 to 1\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "history = [[],[],[],[]]\n",
    "\n",
    "# Constants\n",
    "img_rows, img_cols, img_chan = 28, 28, 1\n",
    "img_shape = (img_rows, img_cols, img_chan)\n",
    "num_classes = 10\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 22000\n",
    "latent_dim = 100\n",
    "batch_size = 32\n",
    "half_batch_size = int(batch_size / 2)\n",
    "genrtr_optimizer = optimizers.Adam(lr=0.0002,     # lr default:         0.001\n",
    "                                   beta_1=0.5,    # beta_1 default:     0.9\n",
    "                                   beta_2=0.999,\n",
    "                                   epsilon=None, \n",
    "                                   decay=0.0, \n",
    "                                   amsgrad=False)\n",
    "discrm_optimizer = genrtr_optimizer\n",
    "combnd_optimizer = discrm_optimizer\n",
    "\n",
    "print(\"Matrix Shapes:\")\n",
    "print('x_train:\\t', x_train.shape)\n",
    "print('y_train:\\t', y_train.shape)\n",
    "print(\"img shape:\\t\", img_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Layers: 2 layers: noise, class_labels\n",
    "noise = layers.Input(shape=(latent_dim,))\n",
    "label = layers.Input(shape=(1,), dtype='int32')\n",
    "\n",
    "# Create an embedding\n",
    "label_embedding = layers.Embedding(num_classes, latent_dim)(label)\n",
    "label_embedding = layers.Flatten()(label_embedding)\n",
    "\n",
    "genrtr_input = layers.multiply([noise, label_embedding])\n",
    "\n",
    "# Generator hidden layers\n",
    "genrtr_hidden = layers.Dense(128 * 7 * 7, activation='relu', input_dim=latent_dim)(genrtr_input)\n",
    "genrtr_hidden = layers.Reshape((7, 7, 128))(genrtr_hidden)\n",
    "genrtr_hidden = layers.BatchNormalization(momentum=0.8)(genrtr_hidden)\n",
    "genrtr_hidden = layers.UpSampling2D()(genrtr_hidden)\n",
    "genrtr_hidden = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(genrtr_hidden)\n",
    "genrtr_hidden = layers.BatchNormalization(momentum=0.8)(genrtr_hidden)\n",
    "genrtr_hidden = layers.UpSampling2D()(genrtr_hidden)\n",
    "genrtr_hidden = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(genrtr_hidden)\n",
    "genrtr_hidden = layers.BatchNormalization(momentum=0.8)(genrtr_hidden)\n",
    "\n",
    "generated_image = layers.Conv2D(img_chan, kernel_size=3, padding='same', activation='tanh')(genrtr_hidden)\n",
    "\n",
    "# Finalize the model\n",
    "generator = Model([noise, label], generated_image)\n",
    "generator.compile(loss=['binary_crossentropy'], optimizer=genrtr_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_image = layers.Input(shape=img_shape)\n",
    "\n",
    "discrm_hidden = layers.Conv2D(16, kernel_size=3, strides=2, input_shape=img_shape, padding='same')(d_image)\n",
    "discrm_hidden = layers.LeakyReLU(alpha=0.2)(discrm_hidden)\n",
    "discrm_hidden = layers.Dropout(0.25)(discrm_hidden)\n",
    "\n",
    "discrm_hidden = layers.Conv2D(32, kernel_size=3, strides=2, padding='same')(discrm_hidden)\n",
    "discrm_hidden = layers.ZeroPadding2D(padding=((0,1),(0,1)))(discrm_hidden)\n",
    "discrm_hidden = layers.LeakyReLU(alpha=0.2)(discrm_hidden)\n",
    "discrm_hidden = layers.Dropout(0.25)(discrm_hidden)\n",
    "discrm_hidden = layers.BatchNormalization(momentum=0.8)(discrm_hidden)\n",
    "\n",
    "discrm_hidden = layers.Conv2D(64, kernel_size=3, strides=2, padding='same')(discrm_hidden)\n",
    "discrm_hidden = layers.LeakyReLU(alpha=0.2)(discrm_hidden)\n",
    "discrm_hidden = layers.Dropout(0.25)(discrm_hidden)\n",
    "discrm_hidden = layers.BatchNormalization(momentum=0.8)(discrm_hidden)\n",
    "\n",
    "discrm_hidden = layers.Conv2D(128, kernel_size=3, strides=1, padding='same')(discrm_hidden)\n",
    "discrm_hidden = layers.LeakyReLU(alpha=0.2)(discrm_hidden)\n",
    "discrm_hidden = layers.Dropout(0.25)(discrm_hidden)\n",
    "discrm_hidden = layers.Flatten()(discrm_hidden)\n",
    "\n",
    "target_valid = layers.Dense(1, activation='sigmoid')(discrm_hidden)\n",
    "target_label = layers.Dense(num_classes+1, activation='softmax')(discrm_hidden)\n",
    "\n",
    "discriminator = Model(d_image, [target_valid, target_label])\n",
    "discriminator.compile(loss=['binary_crossentropy','sparse_categorical_crossentropy'], \n",
    "                      optimizer=discrm_optimizer, \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Don't update discriminator during generator training (moving target problem)\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Don't recompile the discriminator so may still be trained independently...\n",
    "target_valid, target_label = discriminator(generated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined model takes generator inputs and has discriminator outputs...\n",
    "combined = Model([noise, label], [target_valid, target_label])\n",
    "combined.compile(loss=['binary_crossentropy','sparse_categorical_crossentropy'], \n",
    "                 optimizer=combnd_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVG(model_to_dot(generator).create(prog='dot', format='svg'))\n",
    "# SVG(model_to_dot(discriminator).create(prog='dot', format='svg'))\n",
    "# SVG(model_to_dot(combined).create(prog='dot', format='svg'))\n",
    "\n",
    "# generator.summary()\n",
    "# discriminator.summary()\n",
    "# combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    idx = np.random.randint(0, x_train.shape[0], half_batch_size)\n",
    "    real_images = x_train[idx]\n",
    "    image_labels = y_train[idx]\n",
    "\n",
    "    # Generated images\n",
    "    input_noise = np.random.normal(0, 1, (half_batch_size, latent_dim))\n",
    "    input_labels = np.random.randint(0, 10, half_batch_size).reshape(-1, 1)\n",
    "    generated_images = generator.predict([input_noise, input_labels])\n",
    "    \n",
    "    valid = np.ones((half_batch_size, 1)) # 1.0 real\n",
    "    fake = np.zeros((half_batch_size, 1)) # 0.0 fake\n",
    "    \n",
    "    # Assign the fake images to the \"extra class\" or \"fake class\"\n",
    "    # on the one-hot encoding for all fake images (they are\n",
    "    # not any of the digits 0-9 since they are -fakes- so\n",
    "    # we don't used the requested generator labels...)\n",
    "    fake_labels = 10 * np.ones(half_batch_size).reshape(-1, 1)\n",
    "    \n",
    "    d_loss_real = discriminator.train_on_batch(real_images, [valid, image_labels])\n",
    "    d_loss_fake = discriminator.train_on_batch(generated_images, [fake, fake_labels])\n",
    "\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "    \n",
    "    # Training the generator...\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    # Note that we are using the combined model to backprop the loss to the generator... \n",
    "    valid = np.ones((batch_size, 1))\n",
    "    # Give them some labels so the generator can learn which digit\n",
    "    # it is trying to fake.\n",
    "    sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "    \n",
    "    # Train the generator\n",
    "    g_loss = combined.train_on_batch([noise, sampled_labels], [valid, sampled_labels])\n",
    "\n",
    "    history[0] += [d_loss[0]]\n",
    "    history[1] += [d_loss[3]]\n",
    "    history[2] += [d_loss[4]]\n",
    "    history[3] += [g_loss[0]]\n",
    "    \n",
    "    # Print progress indicator\n",
    "    print(\"\\r%d [Discriminator Loss: %f, Real/Fake-Acc.: %.2f%%, Classification-Acc: %.2f%%] [Generator Loss: %f]\" % \n",
    "          (epoch, d_loss[0], 100*d_loss[3], 100*d_loss[4], g_loss[0]), end='')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(12,6))\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.plot(history[0])\n",
    "plt.title('Discriminator Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(history[3])\n",
    "plt.title('Generator Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(history[1])\n",
    "plt.plot(history[2])\n",
    "plt.title('Discriminator Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.legend(['Real/Fake', 'Categories'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digit generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = 10, 10\n",
    "noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
    "sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "\n",
    "generated_images = generator.predict([noise, sampled_labels])\n",
    "generated_images = 0.5 * generated_images + 1\n",
    "\n",
    "fig, axs = plt.subplots(r, c)\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(12)\n",
    "count = 0\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow(generated_images[count, :,:,0], cmap='binary')\n",
    "        axs[i,j].axis('off')\n",
    "        count += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
